\chapter{Introduction}

Fidelity of images produced by rendering pipelines is largely affected by the surface
reflectance model used in the rendering process. Physically based reflectance models used in
modern ray tracing engines help achieve a high level of realism. However, materials encountered
on real surfaces are rarely uniform and feature spatially-varying reflectances due to natural
causes such as wear and tear, weathering, and other surface imperfections. Unfortunately, using
procedural techniques to replicate the complexity of real spatially-varying materials largely
relies on handcrafted heuristics which produce results that are subjective in terms of realism.
To record the complexity of real materials, previous
methods~\cite{aittala2016reflectance, aittala2013practical, aittala2015two, deschaintre2018single}
use real photographs of simple flat surfaces to extract spatially-varying bidirectional
reflectance distribution functions (SVBRDFs). However, extracting the SVBRDF for more complex
surfaces with variable curvatures, such as dirt textures on car hulls, is a significantly harder
task not attempted by these methods not only due to the complexity of the surface geometry, but
also because of the non-stationary nature of the SVBRDFs; different areas of the surface would
experience different amounts of weathering, causing the resultant SVBRDF to not exhibit shift
invariance.

Exemplar based synthesis of complex textures is also studied in computer vision applications.
The advent of the GAN~\cite{goodfellow2014generative} paved the way for high fidelity results from
neural network based generative models for texture synthesis and style
transfer~\cite{zhu2017unpaired, isola2017image, zhou2018non}. Unfortunately, the deep learning
approach requires that a model's building blocks consist of differentiable functions. Since
differentiating more complex functions is often impractical, the majority of neural network models
use simple functions with explicit analytical derivatives. However, if we have methods for
differentiating complex functions, we enable opportunities to utilize deep learning methods in
more complex tasks.

Recent work by Li et al.~\cite{li2018differentiable} features a differentiable ray tracer which
makes it possible to take derivatives of images produced by the ray tracer with respect to the
scene description parameters such as surface vertices, material properties, camera parameters,
etc. The ability to take derivatives with respect to scene variables allows us to incorporate the
ray tracing function into deep learning methods to train complex neural network models for
generating surface geometry and textures.

In this thesis we demonstrate an application of a deep learning model for computer graphics
by training a neural network which incorporates the differentiable ray
tracer~\cite{li2018differentiable}. Specifically, we propose and implement a GAN that synthesizes
SVBRDFs of complex surfaces (like a car hull) using a dataset of 2D images of the surfaces. Our model
takes advantage of the differentiable ray tracer to compute a loss on a rendered image and
back-propagate it to train a generator network which synthesizes a realistic albedo texture-map for a
given 3D shape. We leave the synthesis of more complex SVBRDFs featuring specular reflectance,
glossiness, and normal maps as future work.

We present our results when trained on a synthetic dataset. Our dataset consists of rendered images
of car models with a target texture-map generated by a procedural surface weathering texture model
used commonly in computer graphics applications~\cite{bhandari2018procedural}. Unfortunately, for
the scope of this thesis, we are not able to extend our model to successfully learn texture-maps
from real images.